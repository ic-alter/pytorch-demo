{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb2f782",
   "metadata": {},
   "source": [
    "检查torch是否安装成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc8137d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本： 2.7.1+cu118\n",
      "CUDA 可用： True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch 版本：\", torch.__version__)\n",
    "print(\"CUDA 可用：\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4010e81e",
   "metadata": {},
   "source": [
    "## 张量(Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18346d4a",
   "metadata": {},
   "source": [
    "- **张量 (Tensor)**：实质就是PyTorch定义的一种特殊的表示**多维数组**的数据结构。\n",
    "  - 0 维：标量（如 3.14）\n",
    "  - 1 维：向量（如 [1,2,3]）\n",
    "  - 2 维：矩阵（如二维表格）\n",
    "  - n 维：高维数组（如彩色图片就是 3 维：高×宽×通道）\n",
    "- PyTorch 的 Tensor 类似 NumPy 的 ndarray，但额外支持：\n",
    "  - 在 **GPU 上计算**（CUDA 加速）\n",
    "  - 自动记录计算过程，便于 **反向传播和求梯度**\n",
    "- 每个张量都有属性：\n",
    "  - `shape` → 张量的维度信息\n",
    "  - `dtype` → 数据类型（float32, int64 等）\n",
    "  - `device` → 存放设备（CPU 或 GPU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "322aef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[[0.0087, 0.6807, 0.4384, 0.2276],\n",
      "         [0.4577, 0.5093, 0.8631, 0.8098],\n",
      "         [0.5114, 0.0563, 0.6031, 0.1122]],\n",
      "\n",
      "        [[0.6400, 0.7233, 0.1051, 0.1520],\n",
      "         [0.0058, 0.5382, 0.2946, 0.8865],\n",
      "         [0.5383, 0.0450, 0.0089, 0.4948]]]) \n",
      "shape: torch.Size([2, 3, 4]) | dtype: torch.float32 | device: cpu\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2, 3, 4))  #构建一个3维张量，shape为(2, 3, 4)\n",
    "print(\"a:\", a, \"\\nshape:\", a.shape, \"| dtype:\", a.dtype, \"| device:\", a.device)\n",
    "\n",
    "#将a移动到设备\n",
    "if torch.cuda.is_available():\n",
    "    a = a.to(\"cuda\")\n",
    "    print(\"device:\", a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8399f",
   "metadata": {},
   "source": [
    "### Tensor的初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bfedde",
   "metadata": {},
   "source": [
    "1. 常用初始化方法：\n",
    "- `torch.zeros(shape)` → 全 0\n",
    "- `torch.ones(shape)` → 全 1\n",
    "- `torch.full(shape, value)` → 指定数值\n",
    "- `torch.rand(shape)` → [0,1) 均匀分布\n",
    "- `torch.randn(shape)` → 标准正态分布\n",
    "- `torch.eye(n)` → 单位矩阵\n",
    "- `torch.arange(start, end, step)` → 连续整数\n",
    "- `torch.linspace(start, end, steps)` → 一个范围内等间隔的序列\n",
    "\n",
    "2. torch.xxx_like方法：\n",
    "\n",
    "表示创建一个新的张量，它的形状shape和dtype默认与给定的tensor相同，只是填充值或初始化方式不同。例如`torch.zeros_like(x)`,`torch.ones_like(x)`\n",
    "\n",
    "3. 从已有数组或列表创建\n",
    "\n",
    "可以使用torch.tensor()方法，如果是numpy数组可以使用 torch.from_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f05f1c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5]),\n",
       " tensor([1., 1., 1., 1., 1., 1.]),\n",
       " tensor([[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]),\n",
       " tensor([[1, 4, 7],\n",
       "         [2, 5, 8],\n",
       "         [3, 6, 9]]),\n",
       " tensor([0.0000, 1.5000, 3.0000, 4.5000, 6.0000]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 6)\n",
    "y = torch.ones_like(x, dtype=torch.float32)\n",
    "z = torch.eye(3)   # 单位阵\n",
    "w = torch.tensor([[1, 4, 7], [2, 5, 8], [3, 6, 9]])\n",
    "t = torch.linspace(0,6,5)\n",
    "x,y,z,w,t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce052b",
   "metadata": {},
   "source": [
    "### Tensor的基本运算\n",
    "\n",
    "- 元素级运算： +, -, *, /\n",
    "- 点积(仅适用于1D向量) `torch.dot(x, y)` \n",
    "- 重新组织数据形状： `tensor.reshape(shape)`\n",
    "- 转置： `tensor.t()`或`tensor.T` \n",
    "- 矩阵乘法： `torch.matmul(x, y)`\n",
    "- 求和、平均值、max、min： `torch.sum(x)` `torch.mean(x)` `torch.max(x)` `torch.min(x)` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4a51589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+:  tensor([[1., 2., 6.],\n",
      "        [9., 5., 9.]])\n",
      "*:  tensor([[ 0.,  1.,  8.],\n",
      "        [18.,  4., 20.]])\n",
      "-:  tensor([[-1.,  0., -2.],\n",
      "        [-3.,  3.,  1.]])\n",
      "/:  tensor([[0.0000, 1.0000, 0.5000],\n",
      "        [0.5000, 4.0000, 1.2500]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[0., 1., 2.], [3., 4., 5.]])\n",
    "tensor2 = torch.tensor([[1., 1., 4.], [6., 1., 4.]])\n",
    "print(\"+: \", tensor1 + tensor2)\n",
    "print(\"*: \", tensor1 * tensor2)\n",
    "print(\"-: \", tensor1 - tensor2)\n",
    "print(\"/: \", tensor1 / tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0037c32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_tensor1 = torch.tensor([1. ,2. ,3.])\n",
    "dot_tensor2 = torch.tensor([2. ,3. ,4.])\n",
    "torch.dot(dot_tensor1, dot_tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97214d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor3:  tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "tensor3 = tensor1.reshape(2,3)\n",
    "print(\"tensor3: \", tensor3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b39af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor3.T:  tensor([[0., 3.],\n",
      "        [1., 4.],\n",
      "        [2., 5.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"tensor3.T: \", tensor3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a2a9967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul:  tensor([[ 5., 14.],\n",
      "        [14., 50.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"matmul: \", torch.matmul(tensor3, tensor3.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a14c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:  tensor(15.)\n",
      "mean:  tensor(2.5000)\n",
      "max:  tensor(5.)\n",
      "min:  tensor(0.)\n",
      "argmax：  tensor(4)\n",
      "mean dim0:  tensor([1.5000, 2.5000, 3.5000])\n",
      "mean dim1:  tensor([1., 4.])\n"
     ]
    }
   ],
   "source": [
    "print(\"sum: \", torch.sum(tensor3))\n",
    "print(\"mean: \", torch.mean(tensor3))\n",
    "print(\"max: \", torch.max(tensor3))\n",
    "print(\"min: \", torch.min(tensor3))\n",
    "print(\"argmax： \", torch.argmax(tensor3))\n",
    "\n",
    "print(\"mean dim0: \", torch.mean(tensor3, dim=0))\n",
    "print(\"mean dim1: \", torch.mean(tensor3, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fd3d5",
   "metadata": {},
   "source": [
    "### Tensor的广播机制\n",
    "广播是 PyTorch 在 形状不同的张量 进行运算时的一种 自动扩展机制。\n",
    "\n",
    "它会沿着 维度为 1 或缺失的维度 自动复制数据，使两个张量形状兼容，从而完成逐元素运算。\n",
    "\n",
    "广播的具体规则为：\n",
    "- 从最后一个维度开始逐个比较两个张量的形状。\n",
    "- 如果维度相同，继续比较。\n",
    "- 如果某个维度不相同，但其中一个是 1，就会广播扩展。\n",
    "- 否则，报错（形状不兼容）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1856921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# sample 1\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # 形状 [2,3]\n",
    "y = torch.tensor([10, 20, 30]) # 形状 [3]\n",
    "print(x + y) # y沿着第0维复制成 [[10, 20, 30], [10, 20, 30]]\n",
    "\n",
    "# sample 2\n",
    "a = torch.randn(2, 3, 1)  # 形状 [2,3,1]\n",
    "b = torch.randn(1, 1, 4)  # 形状 [1,1,4]\n",
    "print((a + b).shape)      # [2,3,4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
